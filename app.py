# -*- coding: utf-8 -*-
"""PetaniPro.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v-OtNMd_Ilqd1-JxAgZOfKO1TJMf2-nn
"""

!pip install streamlit
!pip install transformers
!pip install torch
!pip install spellchecker
!pip install pyspellchecker
!pip install langdetect
!pip install python-spellchecker

import streamlit as st
from transformers import BertTokenizer, BertForQuestionAnswering
import torch
import re
from spellchecker import SpellChecker

# Initialize spellchecker with custom dictionary
spell = SpellChecker()
spell.word_frequency.load_text_file('/content/kamus.txt')

# Preprocessing function
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = ' '.join([spell.correction(word) for word in text.split()])
    return text

# Dictionary of common misspellings and corrections
misspellings_dict = {
    "nitrogn": "nitrogen",
    "pertubuhan": "pertumbuhan",
    # Add more misspellings and corrections
}

def correct_misspellings(text):
    words = text.split()
    corrected_words = [misspellings_dict.get(word, word) for word in words]
    return ' '.join(corrected_words)

# Rule-based FAQ system
faq_data = {
    "apa fungsi nitrogen dalam pertumbuhan tanaman": "Nitrogen adalah nutrisi penting bagi tanaman. Ini adalah komponen utama klorofil, senyawa yang digunakan tanaman dalam fotosintesis.",
    "bagaimana mengendalikan hama pada tanaman padi": "Pengendalian Hama Terpadu (PHT) adalah cara paling efektif untuk mengendalikan hama pada tanaman padi. Ini termasuk menggunakan varietas tahan, agen pengendali biologis, dan praktik irigasi yang tepat.",
    # Add more FAQs here
}

def get_rule_based_answer(question):
    return faq_data.get(question)

# Load pre-trained multilingual BERT model and tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')
model = BertForQuestionAnswering.from_pretrained('bert-base-multilingual-cased')

def get_model_based_answer(question, context):
    inputs = tokenizer(question, context, return_tensors='pt')
    input_ids = inputs['input_ids'].tolist()[0]
    outputs = model(**inputs)
    answer_start_scores = outputs.start_logits
    answer_end_scores = outputs.end_logits
    answer_start = torch.argmax(answer_start_scores)
    answer_end = torch.argmax(answer_end_scores) + 1
    answer = tokenizer.convert_tokens_to_ids(input_ids[answer_start:answer_end])
    return tokenizer.decode(answer)

# Streamlit app interface
st.title("PetaniPro - Sistem Basis Pengetahuan dan FAQ Pertanian")
st.write("Masukkan pertanyaan Anda dalam Bahasa Indonesia:")

question = st.text_input("Pertanyaan:")

if question:
    cleaned_question = preprocess_text(question)
    corrected_question = correct_misspellings(cleaned_question)
    answer = get_rule_based_answer(corrected_question)

    if not answer:
        context = "Nitrogen adalah nutrisi penting bagi tanaman. Ini adalah komponen utama klorofil, senyawa yang digunakan tanaman dalam fotosintesis..."  # Example context
        answer = get_model_based_answer(corrected_question, context)

    st.write("Jawaban:", answer)